{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end-non-blind-deconvolution\n",
    "\n",
    "This notebook builds an end-to-end non-blind-deconvolution train rgd optimizer using and torch==1.10 \n",
    "\n",
    "## 1. Problem\n",
    "\n",
    "Non blind deconvolution\n",
    "we have blure image and the kernel that has been used to be blured, we need to get the laten image \n",
    "y = k ∗ x + n\n",
    "\n",
    "* y ∈ R^m : blurred image \n",
    "* k ∈ R^l : corresponding blur kernel k\n",
    "* x ∈ R^n : latent image  \n",
    "* ∗ denotes the convolution operator\n",
    "* n ∈ R^m : denotes an i.i.d. white Gaussian noise term with unknown standard deviation (i.e. noise level).\n",
    "\n",
    "givin y and k, we need to estimate x\n",
    "\n",
    "k is the psf of an eye of individuals having refractive vision problems. !\n",
    "\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "The data we're using till now: *DATASET FROM HRTR: http://chaladze.com/l5/* \n",
    "//could be updated later\n",
    "\n",
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "The evaluation is **PSNR** and **SSIM** //not commited yet\n",
    "Now is also visualisation of output photos VS originl photos 'ground truth'\n",
    "\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "Some information about the data:\n",
    "* We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning.\n",
    "* We're generating dataset : blur kernel k, and n noise , and then y by ourself   \n",
    "* \n",
    "* . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first test add \n",
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our workspace ready\n",
    "\n",
    "* Reload all modules (except those excluded by %aimport) automatically now. '%autoreload'\n",
    "* Reload all modules (except those excluded by %aimport) every time before executing the Python code typed. '%autoreload 2' ✅\n",
    "* Import torch=1.10 ✅\n",
    "* Make sure we're using a GPU ✅\n",
    "* install lib  pydoe, torchsummary, torchmetrics, piq ✅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install pydoe -q\n",
    "# !pip install torchsummary -q\n",
    "# !pip install torchmetrics -q\n",
    "# !pip install piq -q\n",
    "\n",
    "\n",
    "# !pip install torch==1.10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 1.10.0+cu102\n",
      "GPU available (YESSSS!!!!!)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary tools\n",
    "import torch \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"TF version:\", torch.__version__)\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"GPU\", \"available (YESSSS!!!!!)\" if torch.cuda.is_available() else \"not available :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data ready (turning into Tensors)\n",
    "\n",
    "With all machine learning models, our data has to be in numerical format. So that's what we'll be doing first. Turning our images into Tensors (numerical representations).\n",
    "\n",
    "Let's start by accessing our data and checking out the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have\n",
      "Train files: 6000\n",
      "Test files:2000\n"
     ]
    }
   ],
   "source": [
    "# Checkout our data\n",
    "DATA_DIR = \"/home/jovyan/Sarasweet/rgdn-optimizer-based-deconvolution/dataFiles/Linnaeus 5 256X256/\"\n",
    "\n",
    "#How many images we have \n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "train_dir = Path(os.path.join(DATA_DIR, 'train'))\n",
    "test_dir = Path(os.path.join(DATA_DIR, 'test'))\n",
    "\n",
    "train_files = list(train_dir.rglob('*.jpg'))\n",
    "test_files = list(test_dir.rglob('*.jpg'))\n",
    "\n",
    "print('We have\\nTrain files: {}\\nTest files:{}'.format(len(train_files), len(test_files)))\n",
    "\n",
    "\n",
    "#train_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing (80/20 is indeed a good starting point) but Now it's 75/25 as the files\n",
    "# Split the training data into training and validation (again, 80/20 is a fair split)\n",
    "#show every type file and how much of eah photo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
